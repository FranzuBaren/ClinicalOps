<p align="center">
  <img src="https://img.shields.io/badge/%F0%9F%A7%AC-ClinOps_AI-1A3C6E?style=for-the-badge&labelColor=E8F0FE" alt="ClinOps AI" height="40">
</p>

<h3 align="center">Deep Learning for Clinical Trial Safety Intelligence</h3>

<p align="center">
  <em>An end-to-end pipeline on real FDA-grade CDISC data â€”<br>from SAS binary parsing to interpretable neural safety predictions</em>
</p>

<p align="center">
  <img src="https://img.shields.io/badge/Python-3.10+-3776AB?style=flat-square&logo=python&logoColor=white">
  <img src="https://img.shields.io/badge/PyTorch-2.x-EE4C2C?style=flat-square&logo=pytorch&logoColor=white">
  <img src="https://img.shields.io/badge/Data-PHUSE_CDISC_Pilot-00599C?style=flat-square">
  <img src="https://img.shields.io/badge/Subjects-254-2E7D32?style=flat-square">
  <img src="https://img.shields.io/badge/Figures-9_Publication_Quality-B2182B?style=flat-square">
  <img src="https://img.shields.io/badge/License-MIT-green?style=flat-square">
</p>

<p align="center">
  <a href="notebooks/01_walkthrough.ipynb">ğŸ““ Notebook</a> Â· 
  <a href="docs/report.pdf">ğŸ“„ Technical Report (14pp, LaTeX)</a> Â· 
  <a href="#results">ğŸ“Š Results</a> Â· 
  <a href="#quick-start">ğŸš€ Quick Start</a>
</p>

---

## ğŸ¯ Purpose

> **Can modern deep learning improve how we monitor clinical trial safety â€” and can we prove it honestly?**

Clinical trials generate rich, structured safety data (adverse events, vitals, labs, exposure) in regulatory-standard formats. Yet the analytical tools used to monitor patient safety â€” frequency tables, static listings, pre-specified TLFs â€” haven't changed meaningfully since 1998.

This project builds a **complete, reproducible pipeline** that takes raw SAS Transport files and produces:

| Output | What It Delivers |
|--------|-----------------|
| ğŸ”¬ **9 publication figures** | Each answers a specific clinical question a DSMB member needs answered |
| ğŸ§  **8-model ablation study** | Quantifies exactly what each neural component contributes |
| ğŸ” **Per-patient explanations** | Integrated Gradients attribution â€” not a black box |
| âš ï¸ **Honest limitations** | Including a leakage bug we caught, fixed, and documented |

---

## ğŸ“‹ The Problem We Solve

A medical monitor overseeing a 254-patient Alzheimer's trial faces four questions that traditional tools **cannot answer**:

```
â“ TEMPORAL     â†’ When do AEs cluster? Is the first month critical, or is this cumulative?
â“ MULTIVARIATE â†’ Pruritus + dizziness + weight loss in one patient â€” signal or noise?
â“ PREDICTIVE   â†’ This subject has 5 mild AEs in 6 weeks. Should I worry?
â“ EXPLAINABLE  â†’ If I escalate to the DSMB, what evidence do I present?
```

**ClinOps AI answers all four.** With math, with figures, with code â€” and with honest acknowledgment of what doesn't work at N=254.

---

## ğŸ—ï¸ Pipeline Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  XPT Parser  â”‚â”€â”€â”€â–¶â”‚  Pydantic v2  â”‚â”€â”€â”€â–¶â”‚  DuckDB SQL  â”‚
â”‚  (pure Pythonâ”‚    â”‚  CDISC rules  â”‚    â”‚  (zero-copy) â”‚
â”‚   ~60 lines) â”‚    â”‚  validation   â”‚    â”‚  analytics   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                                              â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â–¼                                                    â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚  9 Publication   â”‚                              â”‚  Deep Learning     â”‚
          â”‚  Figures         â”‚                              â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
          â”‚  (matplotlib,    â”‚                              â”‚  â”‚ CVAE Aug     â”‚  â”‚
          â”‚   seaborn,       â”‚                              â”‚  â”‚ Pretraining  â”‚  â”‚
          â”‚   300 DPI)       â”‚                              â”‚  â”‚ MLP + MC     â”‚  â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                              â”‚  â”‚ GRU + Attn   â”‚  â”‚
                                                           â”‚  â”‚ Integ. Grad. â”‚  â”‚
                                                           â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                                                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

| Stage | Technology | What It Does |
|:-----:|-----------|-------------|
| **1** | Pure-Python XPT parser | Reads SAS Transport v5 binary without SAS ($15k/yr saved) |
| **2** | Pydantic v2 | Enforces CDISC SDTM business rules at parse time |
| **3** | DuckDB | Zero-copy SQL analytics on Polars DataFrames |
| **4** | matplotlib + seaborn | 9 clinical figures, each with a clear narrative |
| **5** | PyTorch | CVAE augmentation, self-supervised pretraining, 8-model ablation |
| **6** | Integrated Gradients | Axiomatic per-patient feature attribution |

---

## ğŸ“Š Results

### Clinical Analytics

<table>
<tr>
<td width="50%">
<img src="figures/fig01_volcano.png" width="100%">
<p align="center"><b>Fig 1 Â· Volcano Plot</b><br>
<sub>Pruritus, application site reactions, and dizziness are<br>statistically significant safety signals (Fisher exact, p<0.05).<br>This is a <b>dermatological tolerability</b> issue, not systemic toxicity.</sub></p>
</td>
<td width="50%">
<img src="figures/fig03_kaplan_meier.png" width="100%">
<p align="center"><b>Fig 3 Â· Kaplanâ€“Meier</b><br>
<sub>AE-free survival separates by day 15 with clear dose-response.<br>Half of High Dose patients have first AE by day 25.<br><b>Month-1 tolerance predicts long-term safety.</b></sub></p>
</td>
</tr>
<tr>
<td>
<img src="figures/fig02_swimmer.png" width="100%">
<p align="center"><b>Fig 2 Â· Swimmer Plot</b><br>
<sub>Individual AE timelines for top 35 subjects by event count.<br>Early-onset clustering visible in active arms (red).</sub></p>
</td>
<td>
<img src="figures/fig04_temporal_heatmap.png" width="100%">
<p align="center"><b>Fig 4 Â· Temporal Heatmap</b><br>
<sub>Body system Ã— 4-week period. Skin/general disorders dominate<br>weeks 1â€“8; cardiac events appear later â€” different mechanisms.</sub></p>
</td>
</tr>
<tr>
<td>
<img src="figures/fig05_vitals.png" width="100%">
<p align="center"><b>Fig 5 Â· Vitals Over Time</b><br>
<sub>Mean Â± 95% CI for SBP, DBP, Pulse, Weight across visits.<br>No concerning cardiovascular vital sign signal.</sub></p>
</td>
<td>
<img src="figures/fig06_safety_dashboard.png" width="100%">
<p align="center"><b>Fig 6 Â· Safety Dashboard</b><br>
<sub>DSMB-ready 4-panel: AE incidence, severity profile,<br>SAE rate, exposure-response (r=0.93). <b>Complete overview.</b></sub></p>
</td>
</tr>
</table>

### Deep Learning

<table>
<tr>
<td width="50%">
<img src="figures/fig07_ml_dashboard.png" width="100%">
<p align="center"><b>Fig 7 Â· ML Dashboard</b><br>
<sub>(A) AUROC forest plot for 8 models. (B) Ablation: pretraining +0.067,<br>augmentation additive. (C) Calibration. (D) MC Dropout uncertainty.<br>(E) Learning curve. (F) VAE latent space.</sub></p>
</td>
<td width="50%">
<img src="figures/fig09_integrated_gradients.png" width="100%">
<p align="center"><b>Fig 9 Â· Feature Attribution</b><br>
<sub>Integrated Gradients: AE diversity and temporal spread<br>are top SAE predictors â€” a <b>novel insight</b> invisible to<br>traditional frequency tables.</sub></p>
</td>
</tr>
</table>

<img src="figures/fig08_gru_attention.png" width="100%">
<p align="center"><b>Fig 8 Â· GRU + Attention</b> â€” <sub>Temporal sequence analysis. Attention heatmap over SAE subjects, SAE vs non-SAE attention patterns, and training convergence. Note: GRU does not converge with only 3 SAE sequences.</sub></p>

### Ablation Study: What Actually Works

| Model | Type | AUROC | Î” vs Scratch |
|-------|:----:|:-----:|:------------:|
| Logistic Regression | Classical | **0.690** | â€” |
| Random Forest | Classical | 0.348 | â€” |
| Gradient Boosting | Classical | 0.358 | â€” |
| MLP (scratch) | Neural | 0.568 | baseline |
| MLP + pretraining | Neural | 0.635 | +0.067 |
| MLP + pretrain + aug | Neural | 0.656 | +0.088 |
| MLP + aug only | Neural | 0.928* | â€” |
| Full pipeline + MC | Neural | 0.763 | +0.195 |

<sub>*Suspected augmentation overfitting â€” CVAE may generate synthetics too close to real positives within CV folds.</sub>

> **Key finding:** At N=254 with 3 SAE subjects, â„“â‚‚-regularized logistic regression (0.690) outperforms most neural variants. Self-supervised pretraining contributes +0.067 and CVAE augmentation adds +0.021 incrementally. The neural pipeline's value lies not in raw AUROC but in **interpretability** â€” attention weights and Integrated Gradients reveal patterns no classical model can explain.

---

## âš ï¸ Honest Limitations

This project prioritizes **honest reporting** over impressive numbers:

| Issue | Impact | Status |
|-------|--------|:------:|
| **Data leakage** â€” `n_sae` was both feature and target | AUROC inflated to ~1.0 | âœ… Fixed |
| **3 SAE subjects** out of 254 (1.2%) | All models underpowered | ğŸ“Š Documented |
| **MLP+aug anomaly** (0.928) | Likely CVAE overfitting within folds | âš ï¸ Flagged |
| **Tree ensembles below chance** (0.35) | Imbalance overwhelms RF/GBM | ğŸ“Š Documented |
| **GRU non-convergence** | 3 positive sequences insufficient | ğŸ“Š Documented |
| **Single trial** | Generalizability unknown | ğŸ“‹ Noted |

---

## ğŸš€ Quick Start

```bash
# Clone
git clone https://github.com/YOUR_USERNAME/clinops-ai.git
cd clinops-ai

# Install
pip install -r requirements.txt

# Run â€” data downloads automatically from PHUSE GitHub
jupyter lab notebooks/01_walkthrough.ipynb
```

No SAS license needed. No local data files needed. Everything runs end-to-end.

---

## ğŸ“ Repository Structure

```
clinops-ai/
â”‚
â”œâ”€â”€ ğŸ““ notebooks/
â”‚   â””â”€â”€ 01_walkthrough.ipynb      # Complete pipeline (69 cells, 9 figures)
â”‚
â”œâ”€â”€ ğŸ“„ docs/
â”‚   â”œâ”€â”€ report.pdf                # Technical report (14 pages, JCDE-style LaTeX)
â”‚   â””â”€â”€ report.tex                # LaTeX source (compilable)
â”‚
â”œâ”€â”€ ğŸ“Š figures/                   # All 9 publication figures from real data
â”‚   â”œâ”€â”€ fig01_volcano.png
â”‚   â”œâ”€â”€ fig02_swimmer.png
â”‚   â”œâ”€â”€ fig03_kaplan_meier.png
â”‚   â”œâ”€â”€ fig04_temporal_heatmap.png
â”‚   â”œâ”€â”€ fig05_vitals.png
â”‚   â”œâ”€â”€ fig06_safety_dashboard.png
â”‚   â”œâ”€â”€ fig07_ml_dashboard.png
â”‚   â”œâ”€â”€ fig08_gru_attention.png
â”‚   â””â”€â”€ fig09_integrated_gradients.png
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ LICENSE                       # MIT
â””â”€â”€ README.md                     # You are here
```

---

## ğŸ“š Data

**PHUSE CDISC Pilot Study (CDISCPILOT01)** â€” publicly available, FDA-standard clinical trial dataset.

| | Details |
|---|---|
| **Study** | Xanomeline transdermal (54mg, 81mg) vs Placebo |
| **Population** | 254 subjects, mild-to-moderate Alzheimer's disease |
| **Format** | SAS Transport v5 (XPT) per 21 CFR Part 11 |
| **Domains** | DM (254), AE (1,191), EX (591), VS (6,208), LB (13,988), DS (254) |
| **Source** | [github.com/phuse-org/phuse-scripts](https://github.com/phuse-org/phuse-scripts/tree/master/data/sdtm/cdiscpilot01) |
| **License** | PHUSE open-source, public for research & education |
| **Privacy** | Fully anonymized; synthetic IDs only; no HIPAA PHI |

> âš ï¸ **Disclaimer:** This is a pilot/demonstration dataset. Analyses are methodological demonstrations, not clinical evaluations of Xanomeline.

---

## ğŸ”¬ Methods at a Glance

<details>
<summary><b>Statistical Methods</b> (click to expand)</summary>

- **Disproportionality:** Fisher's exact test on 2Ã—2 tables, volcano plot with logâ‚‚(RR) vs -logâ‚â‚€(p)
- **Survival:** Kaplanâ€“Meier with Greenwood variance, 95% CI bands, number-at-risk table
- **Exposureâ€“Response:** Pearson correlation with t-test (r=0.93, p<0.001)
- **Severity:** Multinomial proportions by arm, stacked bar visualization

</details>

<details>
<summary><b>Deep Learning Components</b> (click to expand)</summary>

- **CVAE:** Conditional VAE with Î²=0.3, latent dim=8, ELBO optimization, reparameterization trick
- **Pretraining:** Masked feature autoencoder (30% masking, BERT-style), 300 epochs
- **Classifier:** Frozen encoder + 2-layer head, MC Dropout (T=50) for epistemic uncertainty
- **GRU:** Bidirectional with Bahdanau attention, leakage-free event encoding [day, severity, SOC]
- **Attribution:** Integrated Gradients with M=200 steps, completeness axiom verified

</details>

<details>
<summary><b>Evaluation Protocol</b> (click to expand)</summary>

- 5-fold stratified CV preserving 1.2% class ratio
- Bootstrap 95% CI (B=2000) on AUROC, Average Precision, Brier score
- 8 models under identical protocol: 3 classical + 5 neural ablation variants

</details>

---

## ğŸ“– Technical Report

The accompanying [LaTeX report](docs/AI_ClinOps.pdf) (14 pages, JCDE journal style) includes:
- Complete mathematical formulation for all statistical and ML methods
- 10 formally defined equations (Fisher, KM, ELBO, GRU gates, Integrated Gradients, etc.)
- Full ablation results with confidence intervals
- Honest limitations section
- Data provenance and licensing statement
- References to foundational literature (Sundararajan, Kingma, Gal, Bahdanau, etc.)

---

<p align="center">
  <sub>Built with Python, PyTorch, and honest methodology Â· MIT License</sub>
</p>
